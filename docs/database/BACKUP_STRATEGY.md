# EstratÃ©gia de Backup - Assist Move Assist
## Backup e RecuperaÃ§Ã£o para ProduÃ§Ã£o

### Ãndice
1. [VisÃ£o Geral da EstratÃ©gia](#visÃ£o-geral-da-estratÃ©gia)
2. [Tipos de Backup](#tipos-de-backup)
3. [Cronograma de Backups](#cronograma-de-backups)
4. [Scripts de AutomaÃ§Ã£o](#scripts-de-automaÃ§Ã£o)
5. [Armazenamento e RetenÃ§Ã£o](#armazenamento-e-retenÃ§Ã£o)
6. [Procedimentos de RestauraÃ§Ã£o](#procedimentos-de-restauraÃ§Ã£o)
7. [Testes de RecuperaÃ§Ã£o](#testes-de-recuperaÃ§Ã£o)
8. [Monitoramento e Alertas](#monitoramento-e-alertas)

---

## VisÃ£o Geral da EstratÃ©gia

### Objetivos
- **RTO (Recovery Time Objective)**: 30 minutos
- **RPO (Recovery Point Objective)**: 1 hora
- **Disponibilidade**: 99.9% (8.76 horas downtime/ano)
- **Integridade**: VerificaÃ§Ã£o automÃ¡tica de backups

### Componentes do Sistema de Backup
1. **Supabase Backups**: Backups automÃ¡ticos diÃ¡rios
2. **Backups Customizados**: Scripts prÃ³prios para dados especÃ­ficos
3. **Storage Backup**: Arquivos e documentos
4. **Configuration Backup**: VariÃ¡veis de ambiente e configuraÃ§Ãµes

---

## Tipos de Backup

### 1. Backup Completo (Full Backup)
```bash
#!/bin/bash
# scripts/backup_full.sh

set -e

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/full"
DATABASE_URL="$VITE_SUPABASE_URL"

echo "ğŸ—„ï¸  Iniciando Backup Completo - $TIMESTAMP"

# Criar diretÃ³rio se nÃ£o existir
mkdir -p $BACKUP_DIR

# Backup do banco de dados completo
echo "ğŸ“Š Backup do banco de dados..."
pg_dump $DATABASE_URL \
    --verbose \
    --clean \
    --no-owner \
    --no-privileges \
    --format=custom \
    --file="$BACKUP_DIR/database_full_$TIMESTAMP.dump"

# Backup do schema apenas (para referÃªncia rÃ¡pida)
pg_dump $DATABASE_URL \
    --schema-only \
    --verbose \
    --clean \
    --no-owner \
    --no-privileges \
    --file="$BACKUP_DIR/schema_$TIMESTAMP.sql"

# Backup de dados especÃ­ficos (dados crÃ­ticos)
psql $DATABASE_URL -c "\copy (SELECT * FROM beneficiarias WHERE status = 'ativa') TO '$BACKUP_DIR/beneficiarias_ativas_$TIMESTAMP.csv' WITH CSV HEADER;"
psql $DATABASE_URL -c "\copy (SELECT * FROM profiles WHERE ativo = true) TO '$BACKUP_DIR/usuarios_ativos_$TIMESTAMP.csv' WITH CSV HEADER;"

# CompressÃ£o do backup
echo "ğŸ—œï¸  Comprimindo backup..."
tar -czf "$BACKUP_DIR/backup_full_$TIMESTAMP.tar.gz" \
    "$BACKUP_DIR/database_full_$TIMESTAMP.dump" \
    "$BACKUP_DIR/schema_$TIMESTAMP.sql" \
    "$BACKUP_DIR/"*.csv

# VerificaÃ§Ã£o da integridade
echo "âœ… Verificando integridade..."
if [ -f "$BACKUP_DIR/backup_full_$TIMESTAMP.tar.gz" ]; then
    SIZE=$(stat -f%z "$BACKUP_DIR/backup_full_$TIMESTAMP.tar.gz" 2>/dev/null || stat -c%s "$BACKUP_DIR/backup_full_$TIMESTAMP.tar.gz")
    if [ $SIZE -gt 1000000 ]; then  # MÃ­nimo 1MB
        echo "âœ… Backup completo criado com sucesso: $SIZE bytes"
        
        # Log do backup
        echo "$(date): Backup Full - Sucesso - $SIZE bytes" >> /var/log/backup.log
        
        # Cleanup arquivos temporÃ¡rios
        rm -f "$BACKUP_DIR/database_full_$TIMESTAMP.dump"
        rm -f "$BACKUP_DIR/schema_$TIMESTAMP.sql"
        rm -f "$BACKUP_DIR/"*.csv
    else
        echo "âŒ Erro: Backup muito pequeno"
        exit 1
    fi
else
    echo "âŒ Erro: Arquivo de backup nÃ£o foi criado"
    exit 1
fi

echo "ğŸ‰ Backup completo finalizado"
```

### 2. Backup Incremental
```bash
#!/bin/bash
# scripts/backup_incremental.sh

set -e

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/incremental"
LAST_BACKUP_FILE="/backup/.last_backup_timestamp"

echo "ğŸ“ˆ Iniciando Backup Incremental - $TIMESTAMP"

# Obter timestamp do Ãºltimo backup
if [ -f "$LAST_BACKUP_FILE" ]; then
    LAST_BACKUP=$(cat $LAST_BACKUP_FILE)
    echo "ğŸ“… Ãšltimo backup: $LAST_BACKUP"
else
    LAST_BACKUP=$(date -d "yesterday" +%Y-%m-%d)
    echo "ğŸ“… Primeiro backup incremental, usando: $LAST_BACKUP"
fi

mkdir -p $BACKUP_DIR

# Backup de dados modificados desde o Ãºltimo backup
echo "ğŸ”„ Backup de dados modificados..."

# BeneficiÃ¡rias modificadas
psql $DATABASE_URL -c "\copy (
    SELECT * FROM beneficiarias 
    WHERE updated_at > '$LAST_BACKUP'
) TO '$BACKUP_DIR/beneficiarias_mod_$TIMESTAMP.csv' WITH CSV HEADER;"

# Posts do feed novos/modificados
psql $DATABASE_URL -c "\copy (
    SELECT * FROM feed_posts 
    WHERE created_at > '$LAST_BACKUP' OR updated_at > '$LAST_BACKUP'
) TO '$BACKUP_DIR/feed_posts_mod_$TIMESTAMP.csv' WITH CSV HEADER;"

# Tarefas modificadas
psql $DATABASE_URL -c "\copy (
    SELECT * FROM tarefas 
    WHERE updated_at > '$LAST_BACKUP'
) TO '$BACKUP_DIR/tarefas_mod_$TIMESTAMP.csv' WITH CSV HEADER;"

# Logs de auditoria novos
psql $DATABASE_URL -c "\copy (
    SELECT * FROM audit_logs 
    WHERE timestamp > '$LAST_BACKUP'
) TO '$BACKUP_DIR/audit_logs_$TIMESTAMP.csv' WITH CSV HEADER;"

# CompressÃ£o
tar -czf "$BACKUP_DIR/backup_incremental_$TIMESTAMP.tar.gz" \
    "$BACKUP_DIR/"*_mod_$TIMESTAMP.csv \
    "$BACKUP_DIR/audit_logs_$TIMESTAMP.csv"

# Cleanup
rm -f "$BACKUP_DIR/"*.csv

# Atualizar timestamp do Ãºltimo backup
echo "$TIMESTAMP" > $LAST_BACKUP_FILE

echo "âœ… Backup incremental concluÃ­do"
```

### 3. Backup de Storage (Arquivos)
```bash
#!/bin/bash
# scripts/backup_storage.sh

set -e

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/storage"
SUPABASE_PROJECT_ID="seu-project-id"

echo "ğŸ“ Iniciando Backup de Storage - $TIMESTAMP"

mkdir -p $BACKUP_DIR

# Backup usando Supabase CLI (se disponÃ­vel)
if command -v supabase &> /dev/null; then
    echo "ğŸ“¦ Fazendo backup via Supabase CLI..."
    supabase storage download \
        --project-ref $SUPABASE_PROJECT_ID \
        --bucket images \
        --destination "$BACKUP_DIR/images_$TIMESTAMP/"
    
    supabase storage download \
        --project-ref $SUPABASE_PROJECT_ID \
        --bucket documents \
        --destination "$BACKUP_DIR/documents_$TIMESTAMP/"
else
    echo "âš ï¸  Supabase CLI nÃ£o disponÃ­vel, usando mÃ©todo alternativo..."
    # Implementar backup via API REST se necessÃ¡rio
fi

# CompressÃ£o dos arquivos
echo "ğŸ—œï¸  Comprimindo arquivos..."
tar -czf "$BACKUP_DIR/storage_backup_$TIMESTAMP.tar.gz" \
    "$BACKUP_DIR/images_$TIMESTAMP/" \
    "$BACKUP_DIR/documents_$TIMESTAMP/" 2>/dev/null || true

# Cleanup
rm -rf "$BACKUP_DIR/images_$TIMESTAMP/"
rm -rf "$BACKUP_DIR/documents_$TIMESTAMP/"

echo "âœ… Backup de storage concluÃ­do"
```

---

## Cronograma de Backups

### ConfiguraÃ§Ã£o do Cron
```bash
# /etc/crontab ou crontab -e

# Backup completo - Todos os domingos Ã s 2:00 AM
0 2 * * 0 /opt/assist-move-assist/scripts/backup_full.sh

# Backup incremental - Todos os dias Ã s 6:00 AM (exceto domingo)
0 6 * * 1-6 /opt/assist-move-assist/scripts/backup_incremental.sh

# Backup de storage - Todos os dias Ã s 3:00 AM
0 3 * * * /opt/assist-move-assist/scripts/backup_storage.sh

# Cleanup de backups antigos - Todos os dias Ã s 4:00 AM
0 4 * * * /opt/assist-move-assist/scripts/cleanup_old_backups.sh

# Teste de integridade - Toda segunda-feira Ã s 5:00 AM
0 5 * * 1 /opt/assist-move-assist/scripts/test_backup_integrity.sh

# Backup de configuraÃ§Ãµes - Todo primeiro dia do mÃªs Ã s 1:00 AM
0 1 1 * * /opt/assist-move-assist/scripts/backup_configs.sh
```

### Script de Cleanup
```bash
#!/bin/bash
# scripts/cleanup_old_backups.sh

set -e

BACKUP_BASE="/backup"
RETENTION_FULL=30      # Manter backups completos por 30 dias
RETENTION_INCREMENTAL=7 # Manter backups incrementais por 7 dias
RETENTION_STORAGE=14   # Manter backups de storage por 14 dias

echo "ğŸ§¹ Iniciando limpeza de backups antigos"

# Cleanup backups completos
echo "Removendo backups completos com mais de $RETENTION_FULL dias..."
find "$BACKUP_BASE/full" -name "backup_full_*.tar.gz" -mtime +$RETENTION_FULL -delete

# Cleanup backups incrementais
echo "Removendo backups incrementais com mais de $RETENTION_INCREMENTAL dias..."
find "$BACKUP_BASE/incremental" -name "backup_incremental_*.tar.gz" -mtime +$RETENTION_INCREMENTAL -delete

# Cleanup backups de storage
echo "Removendo backups de storage com mais de $RETENTION_STORAGE dias..."
find "$BACKUP_BASE/storage" -name "storage_backup_*.tar.gz" -mtime +$RETENTION_STORAGE -delete

# Log da limpeza
DELETED_COUNT=$(find "$BACKUP_BASE" -name "*.tar.gz" -mtime +$RETENTION_FULL | wc -l)
echo "$(date): Cleanup - $DELETED_COUNT arquivos removidos" >> /var/log/backup.log

echo "âœ… Limpeza concluÃ­da"
```

---

## Armazenamento e RetenÃ§Ã£o

### Estrutura de DiretÃ³rios
```
/backup/
â”œâ”€â”€ full/                    # Backups completos
â”‚   â”œâ”€â”€ backup_full_20250808_020000.tar.gz
â”‚   â””â”€â”€ backup_full_20250801_020000.tar.gz
â”œâ”€â”€ incremental/             # Backups incrementais
â”‚   â”œâ”€â”€ backup_incremental_20250808_060000.tar.gz
â”‚   â””â”€â”€ backup_incremental_20250807_060000.tar.gz
â”œâ”€â”€ storage/                 # Backups de arquivos
â”‚   â”œâ”€â”€ storage_backup_20250808_030000.tar.gz
â”‚   â””â”€â”€ storage_backup_20250807_030000.tar.gz
â”œâ”€â”€ configs/                 # Backups de configuraÃ§Ã£o
â”‚   â””â”€â”€ configs_20250801_010000.tar.gz
â”œâ”€â”€ .last_backup_timestamp   # Controle de backups incrementais
â””â”€â”€ integrity_tests/         # Logs de testes de integridade
    â””â”€â”€ test_20250808.log
```

### PolÃ­tica de RetenÃ§Ã£o
- **Backups Completos**: 30 dias (4 backups)
- **Backups Incrementais**: 7 dias
- **Backups de Storage**: 14 dias
- **Backups de ConfiguraÃ§Ã£o**: 90 dias
- **Logs de Teste**: 30 dias

### Armazenamento Remoto (Opcional)
```bash
#!/bin/bash
# scripts/sync_to_remote.sh

# AWS S3
aws s3 sync /backup/ s3://assist-move-assist-backups/$(date +%Y/%m)/ \
    --exclude "*" \
    --include "*.tar.gz" \
    --storage-class STANDARD_IA

# Google Cloud Storage
gsutil -m rsync -r -d /backup/ gs://assist-move-assist-backups/$(date +%Y/%m)/

# Azure Blob Storage
az storage blob upload-batch \
    --destination backup-container \
    --source /backup/ \
    --pattern "*.tar.gz"
```

---

## Procedimentos de RestauraÃ§Ã£o

### 1. RestauraÃ§Ã£o Completa
```bash
#!/bin/bash
# scripts/restore_full.sh

set -e

if [ $# -ne 1 ]; then
    echo "Uso: $0 <arquivo_backup>"
    echo "Exemplo: $0 backup_full_20250808_020000.tar.gz"
    exit 1
fi

BACKUP_FILE=$1
RESTORE_DIR="/tmp/restore_$(date +%Y%m%d_%H%M%S)"
DATABASE_URL_RESTORE="$DATABASE_URL"

echo "ğŸ”„ Iniciando RestauraÃ§Ã£o Completa"
echo "ğŸ“ Arquivo: $BACKUP_FILE"

# Verificar se arquivo existe
if [ ! -f "$BACKUP_FILE" ]; then
    echo "âŒ Erro: Arquivo de backup nÃ£o encontrado"
    exit 1
fi

# Criar diretÃ³rio temporÃ¡rio
mkdir -p $RESTORE_DIR
cd $RESTORE_DIR

# Extrair backup
echo "ğŸ“¦ Extraindo backup..."
tar -xzf "$BACKUP_FILE"

# Encontrar arquivo de dump
DUMP_FILE=$(find . -name "*.dump" | head -1)
if [ -z "$DUMP_FILE" ]; then
    echo "âŒ Erro: Arquivo de dump nÃ£o encontrado no backup"
    exit 1
fi

# ATENÃ‡ÃƒO: RestauraÃ§Ã£o irÃ¡ APAGAR dados existentes!
echo "âš ï¸  ATENÃ‡ÃƒO: Esta operaÃ§Ã£o irÃ¡ SUBSTITUIR todos os dados existentes!"
echo "ğŸ—„ï¸  Banco de destino: $DATABASE_URL_RESTORE"
read -p "Continuar? (digite 'CONFIRMO' para prosseguir): " CONFIRM

if [ "$CONFIRM" != "CONFIRMO" ]; then
    echo "âŒ OperaÃ§Ã£o cancelada"
    exit 1
fi

# Criar backup de seguranÃ§a antes da restauraÃ§Ã£o
echo "ğŸ’¾ Criando backup de seguranÃ§a atual..."
pg_dump $DATABASE_URL_RESTORE > "backup_pre_restore_$(date +%Y%m%d_%H%M%S).sql"

# Restaurar banco de dados
echo "ğŸ”„ Restaurando banco de dados..."
pg_restore \
    --clean \
    --if-exists \
    --no-owner \
    --no-privileges \
    --verbose \
    --dbname="$DATABASE_URL_RESTORE" \
    "$DUMP_FILE"

# Verificar restauraÃ§Ã£o
echo "âœ… Verificando restauraÃ§Ã£o..."
BENEFICIARIAS_COUNT=$(psql $DATABASE_URL_RESTORE -t -c "SELECT COUNT(*) FROM beneficiarias;" | xargs)
USERS_COUNT=$(psql $DATABASE_URL_RESTORE -t -c "SELECT COUNT(*) FROM profiles;" | xargs)

echo "ğŸ“Š EstatÃ­sticas pÃ³s-restauraÃ§Ã£o:"
echo "   BeneficiÃ¡rias: $BENEFICIARIAS_COUNT"
echo "   UsuÃ¡rios: $USERS_COUNT"

# Cleanup
cd /
rm -rf $RESTORE_DIR

echo "ğŸ‰ RestauraÃ§Ã£o completa finalizada com sucesso!"
```

### 2. RestauraÃ§Ã£o de Tabela EspecÃ­fica
```bash
#!/bin/bash
# scripts/restore_table.sh

set -e

if [ $# -ne 2 ]; then
    echo "Uso: $0 <arquivo_backup> <nome_tabela>"
    echo "Exemplo: $0 backup_full_20250808.tar.gz beneficiarias"
    exit 1
fi

BACKUP_FILE=$1
TABLE_NAME=$2
RESTORE_DIR="/tmp/restore_table_$(date +%Y%m%d_%H%M%S)"

echo "ğŸ”„ Restaurando tabela: $TABLE_NAME"

mkdir -p $RESTORE_DIR
cd $RESTORE_DIR

# Extrair e restaurar apenas a tabela especÃ­fica
tar -xzf "$BACKUP_FILE"
DUMP_FILE=$(find . -name "*.dump" | head -1)

# Backup da tabela atual
echo "ğŸ’¾ Backup da tabela atual..."
pg_dump $DATABASE_URL -t $TABLE_NAME > "${TABLE_NAME}_backup_$(date +%Y%m%d_%H%M%S).sql"

# Restaurar apenas a tabela especÃ­fica
pg_restore \
    --clean \
    --if-exists \
    --no-owner \
    --no-privileges \
    --verbose \
    --table="$TABLE_NAME" \
    --dbname="$DATABASE_URL" \
    "$DUMP_FILE"

echo "âœ… Tabela $TABLE_NAME restaurada com sucesso"

# Cleanup
cd /
rm -rf $RESTORE_DIR
```

---

## Testes de RecuperaÃ§Ã£o

### Script de Teste de Integridade
```bash
#!/bin/bash
# scripts/test_backup_integrity.sh

set -e

TEST_DB="assist_move_test_$(date +%Y%m%d_%H%M%S)"
BACKUP_DIR="/backup/full"
LOG_FILE="/backup/integrity_tests/test_$(date +%Y%m%d).log"

echo "ğŸ§ª Iniciando Teste de Integridade de Backup" | tee $LOG_FILE

# Encontrar backup mais recente
LATEST_BACKUP=$(ls -t $BACKUP_DIR/backup_full_*.tar.gz | head -1)

if [ -z "$LATEST_BACKUP" ]; then
    echo "âŒ Nenhum backup encontrado" | tee -a $LOG_FILE
    exit 1
fi

echo "ğŸ“ Testando backup: $(basename $LATEST_BACKUP)" | tee -a $LOG_FILE

# Criar banco de teste
echo "ğŸ—„ï¸  Criando banco de teste: $TEST_DB" | tee -a $LOG_FILE
createdb $TEST_DB

# Extrair e restaurar backup no banco de teste
RESTORE_DIR="/tmp/integrity_test_$(date +%Y%m%d_%H%M%S)"
mkdir -p $RESTORE_DIR
cd $RESTORE_DIR

tar -xzf "$LATEST_BACKUP"
DUMP_FILE=$(find . -name "*.dump" | head -1)

# Restaurar no banco de teste
pg_restore \
    --no-owner \
    --no-privileges \
    --verbose \
    --dbname="postgresql://localhost/$TEST_DB" \
    "$DUMP_FILE" 2>&1 | tee -a $LOG_FILE

# Testes de integridade
echo "âœ… Executando testes de integridade..." | tee -a $LOG_FILE

# Teste 1: Verificar se todas as tabelas existem
TABLES_EXPECTED=("profiles" "beneficiarias" "feed_posts" "tarefas" "oficinas")
for table in "${TABLES_EXPECTED[@]}"; do
    COUNT=$(psql postgresql://localhost/$TEST_DB -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_name='$table';" | xargs)
    if [ "$COUNT" -eq 1 ]; then
        echo "âœ… Tabela $table: OK" | tee -a $LOG_FILE
    else
        echo "âŒ Tabela $table: FALTANDO" | tee -a $LOG_FILE
    fi
done

# Teste 2: Verificar dados bÃ¡sicos
BENEFICIARIAS_COUNT=$(psql postgresql://localhost/$TEST_DB -t -c "SELECT COUNT(*) FROM beneficiarias;" | xargs)
USERS_COUNT=$(psql postgresql://localhost/$TEST_DB -t -c "SELECT COUNT(*) FROM profiles;" | xargs)

echo "ğŸ“Š Contadores:" | tee -a $LOG_FILE
echo "   BeneficiÃ¡rias: $BENEFICIARIAS_COUNT" | tee -a $LOG_FILE
echo "   UsuÃ¡rios: $USERS_COUNT" | tee -a $LOG_FILE

# Teste 3: Verificar integridade referencial
ORPHANED_TASKS=$(psql postgresql://localhost/$TEST_DB -t -c "
    SELECT COUNT(*) FROM tarefas t 
    LEFT JOIN beneficiarias b ON t.beneficiaria_id = b.id 
    WHERE t.beneficiaria_id IS NOT NULL AND b.id IS NULL;
" | xargs)

if [ "$ORPHANED_TASKS" -eq 0 ]; then
    echo "âœ… Integridade referencial: OK" | tee -a $LOG_FILE
else
    echo "âš ï¸  Integridade referencial: $ORPHANED_TASKS tarefas Ã³rfÃ£s encontradas" | tee -a $LOG_FILE
fi

# Cleanup
dropdb $TEST_DB
cd /
rm -rf $RESTORE_DIR

echo "ğŸ‰ Teste de integridade concluÃ­do" | tee -a $LOG_FILE
echo "ğŸ“ Log salvo em: $LOG_FILE"
```

### Teste Automatizado Mensal
```bash
#!/bin/bash
# scripts/monthly_recovery_test.sh

echo "ğŸ—“ï¸  Iniciando Teste de RecuperaÃ§Ã£o Mensal"

# Criar ambiente de teste completo
# Restaurar backup em ambiente isolado
# Executar testes funcionais bÃ¡sicos
# Verificar performance
# Gerar relatÃ³rio detalhado

echo "ğŸ“‹ Teste de RecuperaÃ§Ã£o Mensal concluÃ­do"
echo "ğŸ“Š RelatÃ³rio disponÃ­vel em: /backup/reports/monthly_test_$(date +%Y%m).pdf"
```

---

## Monitoramento e Alertas

### Script de Monitoramento
```bash
#!/bin/bash
# scripts/monitor_backups.sh

BACKUP_DIR="/backup"
WEBHOOK_URL="$SLACK_WEBHOOK_URL"  # ou outro sistema de alertas

# Verificar se backup mais recente tem menos de 25 horas
LATEST_BACKUP=$(find $BACKUP_DIR -name "*.tar.gz" -mtime -1 | head -1)

if [ -z "$LATEST_BACKUP" ]; then
    # Enviar alerta
    curl -X POST -H 'Content-type: application/json' \
        --data '{"text":"ğŸš¨ ALERTA: Nenhum backup encontrado nas Ãºltimas 24 horas!"}' \
        $WEBHOOK_URL
    
    echo "âŒ Backup nÃ£o encontrado - alerta enviado"
    exit 1
fi

# Verificar tamanho do backup
SIZE=$(stat -f%z "$LATEST_BACKUP" 2>/dev/null || stat -c%s "$LATEST_BACKUP")
MIN_SIZE=1000000  # 1MB mÃ­nimo

if [ $SIZE -lt $MIN_SIZE ]; then
    curl -X POST -H 'Content-type: application/json' \
        --data '{"text":"âš ï¸  ALERTA: Backup muito pequeno - possÃ­vel problema"}' \
        $WEBHOOK_URL
    
    echo "âš ï¸  Backup pequeno - alerta enviado"
fi

echo "âœ… Monitoramento de backup OK"
```

### Dashboard de Status
```javascript
// Exemplo de endpoint para status de backups
// /api/backup-status

export default async function handler(req, res) {
  const backups = await getBackupStatus();
  
  res.json({
    status: 'healthy',
    lastFullBackup: backups.lastFull,
    lastIncrementalBackup: backups.lastIncremental,
    totalBackups: backups.count,
    totalSize: backups.totalSize,
    oldestBackup: backups.oldest,
    healthScore: calculateHealthScore(backups)
  });
}
```

---

## Checklist de Backup

### ImplementaÃ§Ã£o âœ…
- [ ] Scripts de backup completo criados
- [ ] Scripts de backup incremental configurados
- [ ] Backup de storage implementado
- [ ] Cronogramas configurados
- [ ] Scripts de limpeza implementados
- [ ] Procedimentos de restauraÃ§Ã£o testados

### Testes âœ…
- [ ] Teste de backup completo executado
- [ ] Teste de restauraÃ§Ã£o executado
- [ ] Teste de integridade automatizado
- [ ] Teste de backup incremental validado
- [ ] Procedimento de rollback testado

### Monitoramento âœ…
- [ ] Alertas configurados
- [ ] Dashboard de status criado
- [ ] Logs centralizados
- [ ] MÃ©tricas de performance coletadas
- [ ] RelatÃ³rios automatizados

---

**Data de CriaÃ§Ã£o**: Agosto 2025  
**VersÃ£o**: 1.0  
**Status**: ImplementaÃ§Ã£o ObrigatÃ³ria
